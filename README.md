# JusticeGraph - Intelligent Judicial Analytics Platform

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Phase](https://img.shields.io/badge/Phase-2%20Complete-success)](https://github.com/RudranshKaran/justicegraph)

JusticeGraph is a comprehensive data-driven platform designed to assist the Indian judicial system in reducing case backlogs, optimizing hearing schedules, and improving transparency through data science, machine learning, and intelligent optimization.

## ğŸ¯ Project Vision

Transform judicial operations through:
- **Automated Data Collection** - Scrape and process judicial data from public sources
- **Intelligent Analytics** - Identify bottlenecks, trends, and performance metrics
- **AI-Powered Prioritization** - Rank cases by urgency using ML models
- **Optimized Scheduling** - Generate efficient hearing calendars with constraint programming
- **Predictive Insights** - Forecast case durations and resource needs

## ğŸ“Š Project Status

| Phase | Status | Description |
|-------|--------|-------------|
| **Phase 1** | âœ… Complete | Data collection, parsing, and ETL pipeline |
| **Phase 2** | âœ… Complete | EDA, ML models, prioritization, and scheduling optimization |
| **Phase 3** | ğŸ”„ Planned | Web dashboard, real-time analytics, API development |

---

## ğŸš€ Quick Start - MVP Dashboard

### Launch the Interactive Dashboard

```bash
# Install dependencies
pip install -r requirements_mvp.txt

# Generate sample data (if not already done)
python generate_sample_data.py

# Launch the dashboard
python run_mvp.py
```

**Dashboard will open at:** `http://localhost:8501`

**ğŸ“˜ See [docs/MVP_README.md](docs/MVP_README.md) for complete MVP guide**  
**ğŸ“˜ See [docs/QUICK_START.md](docs/QUICK_START.md) for quick reference**

---

## ğŸ“ Project Structure

```
JusticeGraph/
â”‚
â”œâ”€â”€ ğŸ¨ frontend/                # MVP Dashboard
â”‚   â””â”€â”€ app.py                       # Streamlit web interface
â”‚
â”œâ”€â”€ ğŸ“Š analysis/                # Exploratory Data Analysis
â”‚   â”œâ”€â”€ case_duration_analysis.py    # Case duration metrics
â”‚   â”œâ”€â”€ backlog_trends.py            # Backlog and disposal rates
â”‚   â”œâ”€â”€ court_performance.py         # Court efficiency analysis
â”‚   â””â”€â”€ eda_overview.ipynb           # Interactive EDA notebook
â”‚
â”œâ”€â”€ ğŸ¤– modeling/                # Machine Learning Models
â”‚   â”œâ”€â”€ priority_model.py            # Case prioritization engine
â”‚   â”œâ”€â”€ duration_prediction.py       # ML duration forecasting
â”‚   â””â”€â”€ model_utils.py               # Feature engineering utilities
â”‚
â”œâ”€â”€ âš™ï¸ optimization/            # Scheduling Engine
â”‚   â”œâ”€â”€ scheduler.py                 # Intelligent hearing scheduler
â”‚   â”œâ”€â”€ constraint_builder.py        # Scheduling constraints
â”‚   â””â”€â”€ optimization_utils.py        # Validation and metrics
â”‚
â”œâ”€â”€ ğŸ“ˆ visualization/           # Charts & Visualizations
â”‚   â””â”€â”€ generate_visuals.py          # Plot generation
â”‚
â”œâ”€â”€ ğŸ’¾ data/                    # Data Storage (Layered)
â”‚   â”œâ”€â”€ bronze/                      # Raw scraped data
â”‚   â”œâ”€â”€ silver/                      # Parsed structured data
â”‚   â””â”€â”€ gold/                        # Analysis-ready data
â”‚       â”œâ”€â”€ prioritized_cases.csv
â”‚       â”œâ”€â”€ optimized_schedule.csv
â”‚       â”œâ”€â”€ case_duration_analysis.csv
â”‚       â””â”€â”€ backlog_trends.csv
â”‚
â”œâ”€â”€ ğŸ—„ï¸ models/                  # Data Models
â”‚   â””â”€â”€ data_models.py               # SQLAlchemy ORM schemas
â”‚
â”œâ”€â”€ ğŸŒ ingest/                  # Web Scraping
â”‚   â”œâ”€â”€ cause_list_ingest.py
â”‚   â”œâ”€â”€ case_status_ingest.py
â”‚   â””â”€â”€ judgment_ingest.py
â”‚
â”œâ”€â”€ ğŸ”§ parse/                   # Data Parsing
â”‚   â””â”€â”€ parse_cause_list.py
â”‚
â”œâ”€â”€ ğŸ”„ normalize/               # Data Cleaning
â”‚   â””â”€â”€ clean_text_utils.py
â”‚
â”œâ”€â”€ ğŸ”„ pipelines/               # Workflow Orchestration
â”‚   â””â”€â”€ phase1_pipeline.py           # Data collection pipeline
â”‚
â”œâ”€â”€ ğŸ› ï¸ utils/                   # Shared Utilities
â”‚   â”œâ”€â”€ db_utils.py                  # Database operations
â”‚   â”œâ”€â”€ http_utils.py                # HTTP utilities
â”‚   â”œâ”€â”€ logging_utils.py             # Structured logging
â”‚   â””â”€â”€ io_utils.py                  # File I/O helpers
â”‚
â”œâ”€â”€ âš™ï¸ configs/                 # Configuration
â”‚   â”œâ”€â”€ sources.yaml                 # Data source metadata
â”‚   â””â”€â”€ settings.env                 # Environment variables
â”‚
â”œâ”€â”€ ğŸ“š docs/                    # Documentation
â”‚   â”œâ”€â”€ MVP_README.md                # MVP setup guide
â”‚   â”œâ”€â”€ QUICK_START.md               # Quick reference
â”‚   â”œâ”€â”€ DATA_DICTIONARY.md           # Data schema
â”‚   â”œâ”€â”€ PIPELINE_OVERVIEW.md         # Pipeline architecture
â”‚   â”œâ”€â”€ PHASE2_SUMMARY.md            # Phase 2 details
â”‚   â””â”€â”€ ISSUES_RESOLVED.md           # Bug fixes and resolutions
â”‚
â”œâ”€â”€ generate_sample_data.py    # Sample data generator
â”œâ”€â”€ run_mvp.py                 # MVP launcher
â”œâ”€â”€ setup_mvp.py               # Automated setup
â”œâ”€â”€ test_mvp.py                # Test suite
â”œâ”€â”€ validate_mvp.py            # Validation script
â”œâ”€â”€ requirements_mvp.txt       # Dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ“Š Data Sources

### Currently Supported

- **eCourts Services Portal**: Case status and cause lists
- **High Court Websites**: Delhi HC, Bombay HC, etc. (customizable)
- **NJDG (National Judicial Data Grid)**: Aggregate statistics

### Planned

- **Supreme Court of India**: SCI case database
- **IndianKanoon**: Judgment repository
- **District Courts**: District-level data

## ğŸ“ˆ MVP Features

### Analytics Dashboard ğŸ“Š
- **Case Volume Trends**: Track daily case filing and disposal rates
- **Backlog Analysis**: Visualize pending cases by court and case type
- **Court Performance**: Compare efficiency metrics across jurisdictions
- **Duration Analysis**: Analyze average case resolution times

### Case Prioritization ğŸ¯
- **Smart Scoring**: ML-driven priority calculation based on:
  - Case age and urgency
  - Case type and complexity
  - Historical hearing patterns
- **Filter & Export**: Search by priority, court, or case type
- **CSV Download**: Export prioritized cases for further analysis

### Optimized Scheduling ğŸ“…
- **Intelligent Allocation**: OR-Tools based constraint optimization
- **Judge Workload Balancing**: Ensure equitable case distribution
- **Timeline Visualization**: Gantt chart of scheduled hearings
- **Schedule Export**: Download hearing calendars

## ğŸ§ª Testing

Run the MVP test suite:

```powershell
python test_mvp.py
```

Validate MVP setup:

```powershell
python validate_mvp.py
```

## ğŸ› ï¸ Development

### Code Style

- Follow PEP 8
- Use type hints
- Document with docstrings
- Use `black` for formatting

```powershell
black .
flake8 .
mypy .
```

### Adding a New Data Source

1. Create scraper in `ingest/new_source_ingest.py`
2. Create parser in `parse/parse_new_source.py`
3. Add source metadata to `configs/sources.yaml`
4. Update documentation

## ğŸ“ Logging

All operations are logged with structured JSON format:

```json
{
  "timestamp": "2023-11-15T14:30:22",
  "level": "INFO",
  "logger": "ingest",
  "message": "Scraper completed successfully",
  "scraper_name": "cause_list_ingest",
  "record_count": 150,
  "status": "success"
}
```

Logs are saved to `logs/` directory.

## ğŸ” Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection string | `sqlite:///justicegraph.db` |
| `LOG_LEVEL` | Logging level | `INFO` |
| `REQUEST_TIMEOUT` | HTTP request timeout (seconds) | `30` |
| `RATE_LIMIT_DELAY` | Delay between requests (seconds) | `2.0` |

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes with tests
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## âš ï¸ Disclaimer

This project is for **research and educational purposes only**. Always respect the terms of service of data sources and comply with applicable laws regarding web scraping and data usage.

## ğŸ¯ Roadmap

### Phase 1 - Data Infrastructure âœ…
- âœ… Data collection and scraping framework
- âœ… Parsing and normalization pipeline
- âœ… Database integration (SQLAlchemy ORM)
- âœ… Data validation and quality checks

### Phase 2 - Analytics & Intelligence âœ…
- âœ… Exploratory Data Analysis (EDA)
- âœ… AI-driven case prioritization engine
- âœ… ML-based duration prediction models
- âœ… Intelligent hearing scheduler (OR-Tools)
- âœ… Interactive Streamlit dashboard
- âœ… Data visualizations (Plotly)

### Phase 3 - Production Deployment ğŸ”„
- ğŸ”„ Real-time data updates
- ğŸ”„ REST API development
- ğŸ”„ User authentication and roles
- ğŸ”„ Mobile-responsive interface
- ğŸ”„ Cloud deployment (AWS/Azure)

### Phase 4 - Advanced Features ğŸ“‹
- ğŸ“‹ Natural Language Processing for judgments
- ğŸ“‹ Predictive analytics for case outcomes
- ğŸ“‹ Multi-language support (Hindi, regional languages)
- ğŸ“‹ Integration with eCourts portal
- ğŸ“‹ Public API for researchers

## ğŸ“ Contact

For questions or collaborations:

- **GitHub**: [@RudranshKaran](https://github.com/RudranshKaran)
- **Project**: [justicegraph](https://github.com/RudranshKaran/justicegraph)

---

**Built with â¤ï¸ to improve access to justice in India**
